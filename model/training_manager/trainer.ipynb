{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "bb472f4c",
            "metadata": {},
            "source": [
                "# Feature Engineering & Model Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "256ea456",
            "metadata": {},
            "source": [
                "### Step 1: Install Necessary Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7dd2a12d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install pandas and scikit-learn if not already installed\n",
                "%pip install pandas scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f8186e5",
            "metadata": {},
            "source": [
                "### Step 2: Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "edd90b93",
            "metadata": {},
            "outputs": [],
            "source": [
                "import tkinter as tk\n",
                "from tkinter import filedialog, messagebox\n",
                "import json\n",
                "import pandas as pd\n",
                "import os\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c5adea22",
            "metadata": {},
            "source": [
                "### Step 3: Get for Processed JSON file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "60d0c9ee",
            "metadata": {},
            "outputs": [],
            "source": [
                "selected_file_path = None  # Global to store the confirmed file path\n",
                "\n",
                "def select_file():\n",
                "    global selected_file_path\n",
                "    file_path = filedialog.askopenfilename(\n",
                "        title=\"Select a file\",\n",
                "        filetypes=((\"JSON Files\", \"*.json\"), (\"All Files\", \"*.*\"))\n",
                "    )\n",
                "    \n",
                "    if file_path:\n",
                "        selected_file_path = file_path\n",
                "        label.config(text=file_path)\n",
                "        print(f\"Selected File: {file_path}\")\n",
                "\n",
                "        try:\n",
                "            with open(file_path, 'r', encoding='utf-8') as file:\n",
                "                content = json.load(file)\n",
                "                text_widget.delete(1.0, tk.END)\n",
                "                text_widget.insert(tk.END, json.dumps(content, indent=4))\n",
                "        except Exception as e:\n",
                "            text_widget.delete(1.0, tk.END)\n",
                "            text_widget.insert(tk.END, f\"Error reading file: {e}\")\n",
                "\n",
                "        button_confirm.pack(pady=10)\n",
                "    else:\n",
                "        label.config(text=\"No file selected\")\n",
                "        button_confirm.pack_forget()\n",
                "\n",
                "def confirm_file():\n",
                "    window.destroy()  # Close GUI\n",
                "\n",
                "# --- GUI SETUP ---\n",
                "window = tk.Tk()\n",
                "window.title(\"File Selector\")\n",
                "window.geometry(\"700x400+10+20\")\n",
                "\n",
                "label = tk.Label(window, text=\"No file selected\", width=80)\n",
                "label.pack(pady=20)\n",
                "\n",
                "button_select = tk.Button(window, text=\"Select File\", command=select_file)\n",
                "button_select.pack(pady=10)\n",
                "\n",
                "button_confirm = tk.Button(window, text=\"Load File\", command=confirm_file)\n",
                "\n",
                "text_widget = tk.Text(window, width=80, height=10)\n",
                "text_widget.pack(pady=10)\n",
                "\n",
                "window.mainloop()\n",
                "\n",
                "# --- After GUI closes ---\n",
                "if selected_file_path:\n",
                "    print(f\"\\nConfirmed file path: {selected_file_path}\")\n",
                "else:\n",
                "    print(\"\\nNo file selected.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c33995d1",
            "metadata": {},
            "source": [
                "### Step 4: Load Data from Selected File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feb23c12",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(file_path):\n",
                "    \"\"\"Loads JSON file and converts it to a DataFrame.\"\"\"\n",
                "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
                "        data = json.load(file)\n",
                "    return pd.DataFrame(data)\n",
                "\n",
                "# Load and prepare\n",
                "data = load_data(selected_file_path)\n",
                "data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "10e2f108",
            "metadata": {},
            "source": [
                "### Step 5: Hybrid Feature-Label Extraction"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "61d57309",
            "metadata": {},
            "source": [
                "#### 5.A Structured Data Feature Extraction\n",
                "- Manual Selection\n",
                "- Auto Selection"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3b3a8ef",
            "metadata": {},
            "source": [
                "##### 5.A.1 Define Manual Selection GUI Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c09bd02a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import tkinter as tk\n",
                "from tkinter import messagebox, ttk\n",
                "\n",
                "class ManualFeatureLabelSelector:\n",
                "    def __init__(self, columns):\n",
                "        self.columns = columns\n",
                "        self.selected_sets = []\n",
                "        self.used_combos = set()\n",
                "\n",
                "        self.root = tk.Tk()\n",
                "        self.root.title(\"Manual Feature-Label Selection\")\n",
                "        self.root.geometry(\"450x550\")\n",
                "        self.root.resizable(False, False)\n",
                "\n",
                "        # Instruction Label\n",
                "        instruction_frame = tk.Frame(self.root)\n",
                "        instruction_frame.pack(fill=tk.X, padx=20, pady=10)\n",
                "\n",
                "        instruction = tk.Label(\n",
                "            instruction_frame,\n",
                "            text=\"Step 1: Select a label\\nStep 2: Select one or more features\",\n",
                "            font=(\"Arial\", 11),\n",
                "            anchor=\"w\",\n",
                "            justify=\"left\"\n",
                "        )\n",
                "        instruction.pack(fill=tk.X)\n",
                "\n",
                "        # Label selection\n",
                "        label_frame = tk.Frame(self.root)\n",
                "        label_frame.pack(pady=5, fill=tk.X, padx=20)\n",
                "\n",
                "        tk.Label(label_frame, text=\"Label:\", font=(\"Arial\", 10)).pack(anchor=\"w\")\n",
                "        self.label_var = tk.StringVar()\n",
                "        self.label_dropdown = ttk.Combobox(label_frame, textvariable=self.label_var, state=\"readonly\", font=(\"Arial\", 10))\n",
                "        self.label_dropdown['values'] = self.columns\n",
                "        self.label_dropdown.bind(\"<<ComboboxSelected>>\", self.update_feature_list)\n",
                "        self.label_dropdown.pack(fill=tk.X, pady=5)\n",
                "\n",
                "        # Feature selection\n",
                "        feature_frame = tk.Frame(self.root)\n",
                "        feature_frame.pack(pady=5, fill=tk.BOTH, expand=True, padx=20)\n",
                "\n",
                "        tk.Label(feature_frame, text=\"Select Features:\", font=(\"Arial\", 10)).pack(anchor=\"w\")\n",
                "        self.feature_listbox = tk.Listbox(feature_frame, selectmode=tk.MULTIPLE, exportselection=False, height=12, font=(\"Arial\", 10))\n",
                "        self.feature_listbox.pack(fill=tk.BOTH, expand=True, pady=5)\n",
                "\n",
                "        # Buttons\n",
                "        button_frame = tk.Frame(self.root)\n",
                "        button_frame.pack(pady=15)\n",
                "\n",
                "        self.submit_button = tk.Button(button_frame, text=\"Add Combination\", width=18, font=(\"Arial\", 10), command=self.submit_selection)\n",
                "        self.submit_button.pack(side=tk.LEFT, padx=10)\n",
                "\n",
                "        self.finish_button = tk.Button(button_frame, text=\"Finish & Close\", width=18, font=(\"Arial\", 10), command=self.finish)\n",
                "        self.finish_button.pack(side=tk.RIGHT, padx=10)\n",
                "\n",
                "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
                "        self.root.mainloop()\n",
                "\n",
                "    def update_feature_list(self, event=None):\n",
                "        label = self.label_var.get()\n",
                "        self.feature_listbox.delete(0, tk.END)\n",
                "        for col in self.columns:\n",
                "            if col != label:\n",
                "                self.feature_listbox.insert(tk.END, col)\n",
                "\n",
                "    def submit_selection(self):\n",
                "        label = self.label_var.get()\n",
                "        if not label:\n",
                "            messagebox.showerror(\"Error\", \"Please select a label.\")\n",
                "            return\n",
                "\n",
                "        selected_indices = self.feature_listbox.curselection()\n",
                "        if not selected_indices:\n",
                "            messagebox.showerror(\"Error\", \"Please select at least one feature.\")\n",
                "            return\n",
                "\n",
                "        features = [self.feature_listbox.get(i) for i in selected_indices]\n",
                "        combo_key = (label, frozenset(features))\n",
                "\n",
                "        if combo_key in self.used_combos:\n",
                "            messagebox.showwarning(\"Duplicate\", \"This combination already exists.\")\n",
                "        else:\n",
                "            self.used_combos.add(combo_key)\n",
                "            self.selected_sets.append({\"label\": label, \"features\": features})\n",
                "            messagebox.showinfo(\"Added\", f\"✅ Added:\\nLabel = {label}\\nFeatures = {', '.join(features)}\")\n",
                "\n",
                "    def finish(self):\n",
                "        if messagebox.askokcancel(\"Exit\", \"Are you sure you want to finish and close?\"):\n",
                "            self.root.destroy()\n",
                "\n",
                "    def on_close(self):\n",
                "        self.finish()\n",
                "\n",
                "    def get_selected_sets(self):\n",
                "        return self.selected_sets"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "47bdabe7",
            "metadata": {},
            "source": [
                "##### 5.A.2 Define Auto Feature-Label Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a23805f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from itertools import combinations\n",
                "\n",
                "def generate_auto_combinations(columns):\n",
                "    all_combinations = []\n",
                "    used_combos = set()\n",
                "\n",
                "    total_combinations = 0\n",
                "    for label in columns:\n",
                "        features_candidates = [col for col in columns if col != label]\n",
                "        for r in range(1, len(features_candidates) + 1):\n",
                "            total_combinations += len(list(combinations(features_candidates, r)))\n",
                "\n",
                "    print(f\"\\n✅ Auto-generating {total_combinations} combinations.\")\n",
                "\n",
                "    processed_combinations = 0\n",
                "    for label in columns:\n",
                "        features_candidates = [col for col in columns if col != label]\n",
                "        for r in range(1, len(features_candidates) + 1):\n",
                "            for feature_set in combinations(features_candidates, r):\n",
                "                combo_key = (label, frozenset(feature_set))\n",
                "                if combo_key not in used_combos:\n",
                "                    used_combos.add(combo_key)\n",
                "                    all_combinations.append(\n",
                "                        {\"label\": label, \"features\": list(feature_set)}\n",
                "                    )\n",
                "                    processed_combinations += 1\n",
                "                    print(\n",
                "                        f\"[Combination Processed: {processed_combinations}/{total_combinations}] \"\n",
                "                        f\": {{'label': '{label}', 'features': {list(feature_set)}}}\"\n",
                "                    )\n",
                "\n",
                "    print(f\"\\n✅ Auto-generated {len(all_combinations)} combinations.\")\n",
                "    return all_combinations"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2145c729",
            "metadata": {},
            "source": [
                "##### 5.A.3 Prompt for Manual / Auto Selection Mode"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e94b13ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_user_choice_window():\n",
                "    choice = {\"result\": None}\n",
                "\n",
                "    def set_choice(value):\n",
                "        choice[\"result\"] = value\n",
                "        window.destroy()\n",
                "\n",
                "    window = tk.Tk()\n",
                "    window.title(\"Feature-Label Selection Mode\")\n",
                "    window.geometry(\"400x200\")\n",
                "    window.resizable(False, False)\n",
                "\n",
                "    # Center message\n",
                "    prompt_label = tk.Label(\n",
                "        window,\n",
                "        text=\"How do you want to select\\nlabel and feature combinations?\",\n",
                "        justify=\"center\"\n",
                "    )\n",
                "    prompt_label.pack(pady=30)\n",
                "\n",
                "    # Button Frame\n",
                "    btn_frame = tk.Frame(window)\n",
                "    btn_frame.pack(pady=10)\n",
                "\n",
                "    # Buttons\n",
                "    yes_btn = tk.Button(btn_frame, text=\"Manual\", width=12, font=(\"Arial\", 10),\n",
                "                        command=lambda: set_choice(True))\n",
                "    yes_btn.pack(side=tk.LEFT, padx=15)\n",
                "\n",
                "    no_btn = tk.Button(btn_frame, text=\"Auto\", width=12, font=(\"Arial\", 10),\n",
                "                       command=lambda: set_choice(False))\n",
                "    no_btn.pack(side=tk.RIGHT, padx=15)\n",
                "\n",
                "    window.mainloop()\n",
                "    return choice[\"result\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "811b52d9",
            "metadata": {},
            "source": [
                "##### 5.A.4 Define Driver Function for Hybrid Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dcdaf5eb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def select_feature_label_combinations(df):\n",
                "    columns = df.columns.tolist()\n",
                "    if len(columns) < 2:\n",
                "        raise ValueError(\"\\n❌ Need at least two columns to form features and label.\")\n",
                "\n",
                "    user_choice = get_user_choice_window()\n",
                "    if user_choice is True:\n",
                "        return ManualFeatureLabelSelector(columns)\n",
                "    elif user_choice is False:\n",
                "        return generate_auto_combinations(columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2baca9a1",
            "metadata": {},
            "source": [
                "##### 5.A.5 Prompt for Structured Hybrid Feature-Label Selection (Main Pipeline) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3dc26132",
            "metadata": {},
            "outputs": [],
            "source": [
                "if selected_file_path:\n",
                "    print(f\"\\n📂 Loading: {selected_file_path}\")\n",
                "    print(f\"🧠 Data Preview:\\n{data.head()}\\n\")\n",
                "\n",
                "    feature_label_selector = select_feature_label_combinations(data)\n",
                "    if feature_label_selector:\n",
                "        if isinstance(feature_label_selector, ManualFeatureLabelSelector):\n",
                "            feature_label_list = feature_label_selector.get_selected_sets()\n",
                "        else:\n",
                "            feature_label_list = feature_label_selector\n",
                "\n",
                "        print(\"\\n\\n📦 All selected/generated feature-label set(s):\")\n",
                "        for s in feature_label_list:\n",
                "            print(s)\n",
                "else:\n",
                "    print(\"❌ No file path available to load.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "38c84822",
            "metadata": {},
            "source": [
                "#### 5.B Unstructured Data Feature Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fc5d8e94",
            "metadata": {},
            "outputs": [],
            "source": [
                "if selected_file_path:\n",
                "    print(f\"\\n📂 Loading: {selected_file_path}\")\n",
                "    print(f\"🧠 Data Preview:\\n{data.head()}\\n\")\n",
                "\n",
                "    # Feature-label selection\n",
                "    feature_label_list = [{\"label\": \"tag\", \"features\": [\"sentence\"]}]\n",
                "    if feature_label_list:\n",
                "        print(\"\\n\\n📦 All feature-label set(s):\")\n",
                "        for s in feature_label_list:\n",
                "            print(s)\n",
                "else:\n",
                "    print(\"❌ No file path available to load.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8f95c26e",
            "metadata": {},
            "source": [
                "### Step 6: Split into Train/Test Sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d1ad972",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.impute import SimpleImputer\n",
                "from collections import Counter\n",
                "\n",
                "def split_combinations(df, selected_combinations, test_size=0.2, random_state=42):\n",
                "    split_sets = []\n",
                "    total = len(selected_combinations)\n",
                "\n",
                "    # Initialize the imputer\n",
                "    imputer = SimpleImputer(strategy='most_frequent')\n",
                "\n",
                "    for idx, combo in enumerate(selected_combinations, start=1):\n",
                "        label = combo['label']\n",
                "        features = combo['features']\n",
                "\n",
                "        # Step 1: Expand multi-label rows into multiple single-label rows\n",
                "        expanded_rows = []\n",
                "        for _, row in df.iterrows():\n",
                "            label_value = row[label]\n",
                "            if isinstance(label_value, list):\n",
                "                for item in label_value:\n",
                "                    expanded_rows.append({**{col: row[col] for col in features}, label: item})\n",
                "            else:\n",
                "                expanded_rows.append({**{col: row[col] for col in features}, label: label_value})\n",
                "\n",
                "        # Step 2: Reconstruct the DataFrame\n",
                "        df_expanded = pd.DataFrame(expanded_rows)\n",
                "\n",
                "        # Step 3: Extract X and y from expanded dataframe\n",
                "        X = df_expanded[features]\n",
                "        y = df_expanded[label]\n",
                "\n",
                "        # Step 4: Flatten list-type values in X (if needed)\n",
                "        X = X.map(lambda x: x[0] if isinstance(x, list) else x)\n",
                "\n",
                "        # Step 5: Keep y as original type unless it's object (category) or list\n",
                "        if y.dtype == 'object' or y.map(lambda x: isinstance(x, list)).any():\n",
                "            y = y.astype(str)\n",
                "\n",
                "        # Optional debug\n",
                "        print(f\"\\n🔍 Expanded label sample:\\n{y.value_counts().head()}\\n\")\n",
                "\n",
                "        # Apply imputer to fill missing values in X and y\n",
                "        X_imputed = imputer.fit_transform(X)  # Impute features\n",
                "        y_imputed = imputer.fit_transform(y.values.reshape(-1, 1))  # Impute labels\n",
                "\n",
                "        # Safe stratification check\n",
                "        class_counts = Counter(y)\n",
                "        use_stratify = y.nunique() > 1 and min(class_counts.values()) >= 2\n",
                "        if not use_stratify:\n",
                "            print(\"⚠️ Skipping stratified split due to low class count\")\n",
                "\n",
                "        # Split into train/test\n",
                "        X_train, X_test, y_train, y_test = train_test_split(\n",
                "            X_imputed, y_imputed,\n",
                "            test_size=test_size,\n",
                "            stratify=y if use_stratify else None,\n",
                "            random_state=random_state\n",
                "        )\n",
                "\n",
                "        # Convert X_train and X_test back to DataFrames with column names\n",
                "        X_train = pd.DataFrame(X_train, columns=X.columns)\n",
                "        X_test = pd.DataFrame(X_test, columns=X.columns)\n",
                "        y_train = pd.Series(y_train.ravel(), name=label)\n",
                "        y_test = pd.Series(y_test.ravel(), name=label)\n",
                "\n",
                "        # Append the valid split to the result list\n",
                "        split_sets.append((X_train, X_test, y_train, y_test, X.columns.tolist()))\n",
                "\n",
                "        print(f\"\\n[Split {idx}/{total}]\\n✅ Predictor: '{label}', Features: {features}\")\n",
                "        print(f\"➤ Train size: {len(X_train)}, Test size: {len(X_test)}\\n\")\n",
                "\n",
                "    return split_sets\n",
                "\n",
                "# Run the split function\n",
                "split_sets = split_combinations(data, feature_label_list)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6d9d0306",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7399adfb",
            "metadata": {},
            "outputs": [],
            "source": [
                "for idx, (X_train, X_test, y_train, y_test, features) in enumerate(split_sets):\n",
                "    print(f\"\\n✂️ Split {idx + 1}: {y_test.name}\\n\")\n",
                "    print(\"X_train:\")\n",
                "    print(X_train.head())\n",
                "    print(\"\\ny_train:\")\n",
                "    print(y_train.head())\n",
                "    print(\"\\nX_test:\")\n",
                "    print(X_test.head())\n",
                "    print(\"\\ny_test:\")\n",
                "    print(y_test.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "36bfb32f",
            "metadata": {},
            "source": [
                "### Step 7: Training Model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09e80c60",
            "metadata": {},
            "source": [
                "<p style=\"text-decoration: underline; font-size: 18px; font-weight: bold;\">\n",
                "    Evaluation Metrics by Task Type\n",
                "</p>\n",
                "\n",
                "<!-- REGRESSION METRICS -->\n",
                "<p style=\"color: cyan; font-weight: bold; font-size: 2vw;\">📈 Regression Metrics</p>\n",
                "\n",
                "<ol>\n",
                "    <li><b>R² Score (Coefficient of Determination)</b>\n",
                "        <ul>\n",
                "            <li>Measures how well the model explains the variability of the target variable <code>y</code>.</li>\n",
                "            <li><code>R² = 1.0</code> → Perfect prediction (explains all variance).</li>\n",
                "            <li><code>R² = 0</code> → Model predicts no better than the mean.</li>\n",
                "            <li><code>R² &lt; 0</code> → Model performs worse than a flat line at the mean.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Mean Squared Error (MSE)</b>\n",
                "        <ul>\n",
                "            <li>The average of the squared differences between predicted and actual values.</li>\n",
                "            <li>Smaller values indicate better performance.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Root Mean Squared Error (RMSE)</b>\n",
                "        <ul>\n",
                "            <li>The square root of MSE.</li>\n",
                "            <li>Error is in the same units as the target variable.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Mean Absolute Percentage Error (MAPE)</b>\n",
                "        <ul>\n",
                "            <li>Average percentage error between actual and predicted values.</li>\n",
                "            <li><code>MAPE = 0%</code> means perfect predictions.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "</ol>\n",
                "\n",
                "<!-- CLASSIFICATION METRICS -->\n",
                "<p style=\"color: pink; font-weight: bold; font-size: 2vw;\">🧠 Classification Metrics</p>\n",
                "\n",
                "<ol>\n",
                "    <li><b>Accuracy Score</b>\n",
                "        <ul>\n",
                "            <li>Percentage of correct predictions out of total predictions.</li>\n",
                "            <li><span style=\"color: red; font-weight: bold;\">Applicable only to classification tasks.</span></li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Precision</b>\n",
                "        <ul>\n",
                "            <li><code>Precision = TP / (TP + FP)</code></li>\n",
                "            <li>Measures how many predicted positives are actually correct.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Recall (Sensitivity)</b>\n",
                "        <ul>\n",
                "            <li><code>Recall = TP / (TP + FN)</code></li>\n",
                "            <li>Measures how many actual positives were correctly predicted.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>F1 Score</b>\n",
                "        <ul>\n",
                "            <li><code>F1 = 2 * (Precision * Recall) / (Precision + Recall)</code></li>\n",
                "            <li>Harmonic mean of precision and recall.</li>\n",
                "            <li>Best when you need a balance between precision and recall, especially in imbalanced datasets.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Receiver Operating Characteristic - Area Under the Curve (ROC-AUC)</b>\n",
                "        <ul>\n",
                "            <li>Measures model's ability to distinguish between classes.</li>\n",
                "            <li>Closer to 1.0 means better class separation.</li>\n",
                "            <li><span style=\"color: red; font-weight: bold;\">Applicable only to classification tasks.</span></li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Confidence Score</b>\n",
                "        <ul>\n",
                "            <li>Represents the probability or certainty of the model's prediction for each sample.</li>\n",
                "            <li>Higher confidence means the model is more certain about its prediction.</li>\n",
                "            <li>For classifiers like KNeighborsClassifier, this is often the proportion of neighbors that voted for the predicted class.</li>\n",
                "            <li>Useful for thresholding predictions or identifying uncertain cases.</li>\n",
                "        </ul>\n",
                "    </li>\n",
                "    <li>\n",
                "        <b>Confusion Matrix</b>\n",
                "        <ul>\n",
                "            <li>Summarizes the model’s correct and incorrect predictions for each class.</li>\n",
                "            <li><span style=\"color: red; font-weight: bold;\">Applicable only to classification tasks.</span></li>\n",
                "        </ul>\n",
                "        <table border=\"1\" cellpadding=\"5\" style=\"border-collapse: collapse; margin-top: 10px;\">\n",
                "            <tr>\n",
                "                <th></th>\n",
                "                <th>Predicted: Yes</th>\n",
                "                <th>Predicted: No</th>\n",
                "            </tr>\n",
                "            <tr>\n",
                "                <th>Actual: Yes</th>\n",
                "                <td>TP (True Positive)</td>\n",
                "                <td>FN (False Negative)</td>\n",
                "            </tr>\n",
                "            <tr>\n",
                "                <th>Actual: No</th>\n",
                "                <td>FP (False Positive)</td>\n",
                "                <td>TN (True Negative)</td>\n",
                "            </tr>\n",
                "        </table><br/>\n",
                "    </li>\n",
                "</ol>\n",
                "\n",
                "<hr style=\"margin-top: 20px;\">\n",
                "\n",
                "<p><b>Summary:</b></p>\n",
                "<ul>\n",
                "    <li>Use <span style=\"color: cyan;\"><b>R², MSE, RMSE, MAPE</b></span> for <b>Regression</b> problems.</li>\n",
                "    <li>Use <span style=\"color: pink;\"><b>Accuracy, Precision, Recall, F1 Score, AUC-ROC, Confidence Score, Confusion Matrix</b></span> for <b>Classification</b> problems.</li>\n",
                "</ul>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4385f5a5",
            "metadata": {},
            "source": [
                "#### 7.1 Generic Training Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0cd36a3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from scipy.sparse import csr_matrix\n",
                "\n",
                "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, task_type='regression', target_column='target'):\n",
                "    label_encoder = LabelEncoder()\n",
                "    vectorizer = None\n",
                "    \n",
                "    # --- Preprocessing ---\n",
                "    for col in X_train.columns:\n",
                "        if X_train[col].apply(lambda x: isinstance(x, list)).any():\n",
                "            X_train[col] = X_train[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
                "            X_test[col] = X_test[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
                "\n",
                "    # Apply .str.lower() only to object columns with string values\n",
                "    for col in X_train.select_dtypes(include='object').columns:\n",
                "        if X_train[col].apply(lambda x: isinstance(x, str)).all():\n",
                "            X_train[col] = X_train[col].str.lower()\n",
                "            X_test[col] = X_test[col].str.lower()\n",
                "\n",
                "    # Apply lambda to handle list-type targets\n",
                "    y_train = y_train.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
                "    y_test = y_test.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
                "\n",
                "    label_encoder = None\n",
                "    confidence = None\n",
                "    numerical_features = None\n",
                "\n",
                "    # --- Task-specific Handling ---\n",
                "    if task_type == 'regression':\n",
                "        y_train = pd.to_numeric(y_train, errors='coerce')\n",
                "        y_test = pd.to_numeric(y_test, errors='coerce')\n",
                "\n",
                "        if y_train.isna().any() or y_test.isna().any():\n",
                "            print(\"⚠️ Warning: Some target values are NaN.\")\n",
                "        if y_train.isna().all() or y_test.isna().all():\n",
                "            raise ValueError(\"🚫 All target values are NaN.\")\n",
                "\n",
                "        X_train_encoded = pd.get_dummies(X_train)\n",
                "        X_test_encoded = pd.get_dummies(X_test)\n",
                "        X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "        numerical_features = list(X_train.select_dtypes(exclude='object').columns)\n",
                "\n",
                "    elif task_type == 'classification':\n",
                "        label_encoder = LabelEncoder()\n",
                "        y_train = label_encoder.fit_transform(y_train)\n",
                "\n",
                "        y_test_mask = y_test.isin(label_encoder.classes_)\n",
                "        X_test = X_test[y_test_mask]\n",
                "        y_test = y_test[y_test_mask]\n",
                "\n",
                "        if X_test.empty or y_test.empty:\n",
                "            raise ValueError(\"🚫 After filtering, X_test or y_test is empty. Cannot evaluate model.\")\n",
                "\n",
                "        y_test = label_encoder.transform(y_test)\n",
                "\n",
                "        # if it is a text classification task, then we need to vectorize the text data,\n",
                "        # check on whether the Xtrain is called 'sentence' or not AND Xtest is called 'tag' or not\n",
                "        # if so, we use TfidfVectorizer for text features\n",
                "        if (X_train.columns[0] == 'sentence' and target_column == 'tag' and len(X_train.columns) == 1):\n",
                "            vectorizer = TfidfVectorizer()\n",
                "            X_train_encoded = vectorizer.fit_transform(X_train['sentence'])\n",
                "            X_test_encoded = vectorizer.transform(X_test['sentence'])\n",
                "        \n",
                "        # otherwise we use get_dummies for categorical features\n",
                "        else :\n",
                "            X_train_encoded = pd.get_dummies(X_train)\n",
                "            X_test_encoded = pd.get_dummies(X_test)\n",
                "            X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "    else:\n",
                "        raise ValueError(f\"Unsupported task_type: {task_type}\")\n",
                "\n",
                "    # --- Model Training ---\n",
                "    model.fit(X_train_encoded, y_train)\n",
                "    y_pred = model.predict(X_test_encoded)\n",
                "\n",
                "    # --- Metrics ---\n",
                "    if task_type == 'regression':\n",
                "        r2 = r2_score(y_test, y_pred)\n",
                "        mse = mean_squared_error(y_test, y_pred)\n",
                "        rmse = math.sqrt(mse)\n",
                "        epsilon = 1e-10\n",
                "        nonzero_mask = y_test != 0\n",
                "        mape = np.mean(np.abs((y_test[nonzero_mask] - y_pred[nonzero_mask]) / (y_test[nonzero_mask] + epsilon))) * 100 if np.any(nonzero_mask) else float('nan')\n",
                "\n",
                "        print(f\"📦 Model ({model.__class__.__name__})\")\n",
                "        print(f\"   ➤ R² Score: {r2:.4f}\")\n",
                "        print(f\"   ➤ MSE: {mse:.2f}\")\n",
                "        print(f\"   ➤ RMSE: {rmse:.2f}\")\n",
                "        print(f\"   ➤ MAPE: {mape:.2f}%\")\n",
                "        metrics = {\"r2\": r2, \"mse\": mse, \"rmse\": rmse, \"mape\": mape}\n",
                "\n",
                "    elif task_type == 'classification':\n",
                "        acc = accuracy_score(y_test, y_pred)\n",
                "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
                "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
                "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
                "        try:\n",
                "            roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_encoded), multi_class='ovr') \n",
                "        except ValueError:\n",
                "            roc_auc = None  # If ROC-AUC cannot be computed for certain models\n",
                "        confidence = np.max(model.predict_proba(X_test_encoded), axis=1) if hasattr(model, \"predict_proba\") else None\n",
                "        cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "        print(f\"📦 Model ({model.__class__.__name__})\")\n",
                "        print(f\"   ➤ Accuracy: {acc:.2f}\")\n",
                "        print(f\"   ➤ F1 Score: {f1:.2f}\")\n",
                "        print(f\"   ➤ Precision: {precision:.2f}\")\n",
                "        print(f\"   ➤ Recall: {recall:.2f}\")\n",
                "        print(f\"   ➤ ROC-AUC: {roc_auc:.2f}\" if roc_auc is not None else \"   ➤ ROC-AUC: N/A\")\n",
                "        print(f\"   ➤ Confidence: {np.mean(confidence):.2f}\" if confidence is not None else \"   ➤ Confidence: N/A\")\n",
                "        print(\"   ➤ Confusion Matrix:\")\n",
                "        print(cm)\n",
                "        metrics = {\n",
                "            \"accuracy\": acc,\n",
                "            \"f1\": f1,\n",
                "            \"precision\": precision,\n",
                "            \"recall\": recall,\n",
                "            \"roc_auc\": roc_auc,\n",
                "            \"confusion_matrix\": cm,\n",
                "            \"confidence\": confidence\n",
                "        }\n",
                "\n",
                "    print(\"\\n📦 Predictions\")\n",
                "    print(y_pred)\n",
                "\n",
                "    print(\"\\n📦 Encoded y-test\")\n",
                "    print(y_test)\n",
                "    \n",
                "    return {\n",
                "        # --- Model Info ---\n",
                "        \"model\": model,\n",
                "        \"description\": f\"{model.__class__.__name__}, predicting {target_column} based on {', '.join(X_train.columns)}\",\n",
                "        \"predictor\": target_column,\n",
                "\n",
                "        # --- Feature Info ---\n",
                "        \"features\": list(X_train.columns),\n",
                "        \"X_train_columns\": vectorizer.get_feature_names_out().tolist() if isinstance(X_train_encoded, np.ndarray) or isinstance(X_train_encoded, csr_matrix) else X_train_encoded.columns.tolist(),\n",
                "        \"numerical_features\": numerical_features,\n",
                "\n",
                "        # --- Encoded & Raw Data (optional for inspection or downstream use) ---\n",
                "        \"X_train_encoded\": X_train_encoded,\n",
                "        \"X_test_encoded\": X_test_encoded,\n",
                "        \"X_test\": X_test,\n",
                "        \"y_train\": y_train,\n",
                "        \"y_test\": y_test,\n",
                "\n",
                "        # --- Predictions ---\n",
                "        \"y_pred\": y_pred,\n",
                "        \"confidence\": confidence,\n",
                "\n",
                "        # --- Label Handling ---\n",
                "        \"label_encoder\": label_encoder,\n",
                "\n",
                "        # --- Evaluation Metrics ---\n",
                "        \"metrics\": metrics,\n",
                "        \n",
                "        # --- Return the vectorizer for text classification ---\n",
                "        \"vectorizer\": vectorizer if task_type == 'classification' else None\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "35414932",
            "metadata": {},
            "source": [
                "#### 7.2 Model Selection GUI Definition"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1910dcaf",
            "metadata": {},
            "source": [
                "<table>\n",
                "<tr>\n",
                "<td colspan=\"4\" style=\"font-weight: bold; text-align: center; font-size: 2vw; line-height: 0.15vh\">Model Selection Justification</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td style=\"font-weight: bold; text-align: center;\">Name</td>\n",
                "<td style=\"font-weight: bold; text-align: center;\">Description</td>\n",
                "<td style=\"font-weight: bold; text-align: center;\">Example of Usage</td>\n",
                "<td style=\"font-weight: bold; text-align: center;\">Supervised/Unsupervised</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td style=\"text-align: center;\">Linear Regression</td>\n",
                "<td style=\"text-align: justify;\">Used to predict numbers based on other factors.</td>\n",
                "<td style=\"text-align: justify;\">For example, predicting the \"Minimum Cost per Day\" based on things like District, Vehicle, Travel Time, and Season.</td>\n",
                "<td style=\"text-align: center;\">Supervised</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td style=\"text-align: center;\">Decision Tree</td>\n",
                "<td style=\"text-align: justify;\">A model that makes decisions by asking yes/no questions about the data.</td>\n",
                "<td style=\"text-align: justify;\">If the District is \"Khagrachhari\" and the Tourist Spots include \"Risang Jhorna\", then the Season will be \"Winter\".</td>\n",
                "<td style=\"text-align: center;\">Supervised</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td style=\"text-align: center;\">K-Nearest Neighbors (KNN)</td>\n",
                "<td style=\"text-align: justify;\">Finds the most similar examples from past data and uses them to make predictions.</td>\n",
                "<td style=\"text-align: justify;\">To recommend tourist spots that are similar to \"Risang Jhorna\", based on nearby options in the data.</td>\n",
                "<td style=\"text-align: center;\">Supervised</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td style=\"text-align: center;\">Random Forest</td>\n",
                "<td style=\"text-align: justify;\">Uses many decision trees together to make a better prediction.</td>\n",
                "<td style=\"text-align: justify;\">For example, one tree might say \"Visit Risang Jhorna\" because the District is \"Khagrachhari\" and the Season is \"Winter\", while another tree might say \"Visit Risang Jhorna\" based on different factors like the Vehicle being \"Car\".</td>\n",
                "<td style=\"text-align: center;\">Supervised</td>\n",
                "</tr>\n",
                "</table>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "17b203e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.base import is_classifier\n",
                "from sklearn.base import is_regressor\n",
                "from math import sqrt\n",
                "\n",
                "def get_model(model_name, X_train=None):\n",
                "    \"\"\"\n",
                "    Returns a machine learning model instance based on the model name.\n",
                "    If KNN is selected, number of neighbors is determined by sqrt of training samples.\n",
                "    \n",
                "    Parameters:\n",
                "    - model_name (str): Name of the model.\n",
                "    - X_train (optional): Training features, needed only for KNN to calculate optimal k.\n",
                "    \n",
                "    Returns:\n",
                "    - model: Instantiated ML model\n",
                "    \"\"\"\n",
                "    if model_name == \"Linear Regression\":\n",
                "        return LinearRegression()\n",
                "    elif model_name == \"Decision Tree Regressor\":\n",
                "        return DecisionTreeRegressor()\n",
                "    elif model_name == \"Decision Tree Classifier\":\n",
                "        return DecisionTreeClassifier()\n",
                "    elif model_name == \"K-Nearest Neighbors Regressor\":\n",
                "        k = max(1, int(sqrt(len(X_train)))) if X_train is not None else 5\n",
                "        print(f\"Using {k} neighbors for KNN\")\n",
                "        return KNeighborsRegressor(n_neighbors=k)\n",
                "    elif model_name == \"K-Nearest Neighbors Classifier\":\n",
                "        k = max(1, int(sqrt(len(X_train)))) if X_train is not None else 5\n",
                "        print(f\"Using {k} neighbors for KNN\")\n",
                "        return KNeighborsClassifier(n_neighbors=k)\n",
                "    elif model_name == \"Random Forest Regressor\":\n",
                "        return RandomForestRegressor()\n",
                "    elif model_name == \"Random Forest Classifier\":\n",
                "        return RandomForestClassifier()\n",
                "    else:\n",
                "        raise ValueError(f\"🚫 Unknown model name: {model_name}\")\n",
                "\n",
                "def select_model_gui(features, label, feature_names=None, label_name=None):\n",
                "    \"\"\"\n",
                "    Tkinter GUI to select model based on label type.\n",
                "    Displays selected features and label for clarity.\n",
                "    \"\"\"\n",
                "\n",
                "    selected_model = None\n",
                "\n",
                "    def select_model(model):\n",
                "        nonlocal selected_model\n",
                "        selected_model = model\n",
                "        print(f\"\\n✅ Selected model: {model}\")\n",
                "        window.quit()\n",
                "        window.destroy()\n",
                "\n",
                "    # --- Label type analysis ---\n",
                "    label_is_categorical = label.dtype == 'object' or label.dtype.name == 'category'\n",
                "    try:\n",
                "        _ = pd.to_numeric(label, errors='coerce')\n",
                "        label_is_numeric = not label_is_categorical and label.dropna().apply(lambda x: isinstance(x, (int, float))).all()\n",
                "    except:\n",
                "        label_is_numeric = False\n",
                "\n",
                "    # --- GUI setup ---\n",
                "    window = tk.Tk()\n",
                "    window.title(\"Model Selector\")\n",
                "    window.geometry(\"650x600+50+50\")\n",
                "\n",
                "    tk.Label(window, text=\"🤖 Click to Select a Machine Learning Model\", font=(\"Arial\", 14, \"bold\")).pack(pady=10)\n",
                "\n",
                "    # --- Display selected features and label ---\n",
                "    if isinstance(features, list):\n",
                "        feature_text = \", \".join(features)\n",
                "    else:\n",
                "        feature_text = \", \".join(features.columns) if features is not None else \", \".join(feature_names)\n",
                "\n",
                "    label_text = label_name if label_name else label.name if label.name else \"Label\"\n",
                "\n",
                "    tk.Label(window, text=f\"🎯 Label: {label_text}\", font=(\"Arial\", 11), wraplength=600, justify=\"left\", fg=\"dark green\").pack(pady=5)\n",
                "    tk.Label(window, text=f\"📌 Features: {feature_text}\", font=(\"Arial\", 11), wraplength=600, justify=\"left\", fg=\"blue\").pack(pady=10)\n",
                "\n",
                "    # --- Model options ---\n",
                "    if label_is_categorical:\n",
                "        models = [\n",
                "            \"Decision Tree Classifier\",\n",
                "            \"K-Nearest Neighbors Classifier\",\n",
                "            \"Random Forest Classifier\"\n",
                "        ]\n",
                "    else:\n",
                "        models = [\n",
                "            \"Linear Regression\",\n",
                "            \"Decision Tree Regressor\",\n",
                "            \"K-Nearest Neighbors Regressor\",\n",
                "            \"Random Forest Regressor\"\n",
                "        ]\n",
                "\n",
                "    for model_name in models:\n",
                "        button = tk.Button(window, text=model_name, width=45, pady=10,\n",
                "                           command=lambda name=model_name: select_model(name))\n",
                "        button.pack(pady=5)\n",
                "\n",
                "    window.mainloop()\n",
                "    return selected_model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20991cbb",
            "metadata": {},
            "source": [
                "#### 7.3 Model Selection & Training (Main Operation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f093193",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Assuming split_sets and feature_label_list are already defined\n",
                "trained_models = []\n",
                "\n",
                "for idx, (X_train, X_test, y_train, y_test, feature_names) in enumerate(split_sets, start=1):\n",
                "    print(f\"\\n🔄 Training split {idx}/{len(split_sets)}\")\n",
                "\n",
                "    # Flatten list-type targets if present\n",
                "    y_train = y_train.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
                "    y_test = y_test.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
                "\n",
                "    # If data is still numpy arrays, convert to DataFrame\n",
                "    if isinstance(X_train, np.ndarray):\n",
                "        X_train = pd.DataFrame(X_train, columns=feature_names)\n",
                "        X_test = pd.DataFrame(X_test, columns=feature_names)\n",
                "\n",
                "    # Try converting to numeric to check if it's suitable for regression\n",
                "    y_train_numeric = pd.to_numeric(y_train, errors='coerce')\n",
                "    y_test_numeric = pd.to_numeric(y_test, errors='coerce')\n",
                "\n",
                "    label_is_numeric = not y_train_numeric.isna().all()\n",
                "\n",
                "    # Choose the appropriate label for GUI display and training\n",
                "    label_for_gui = y_train_numeric if label_is_numeric else y_train\n",
                "\n",
                "    # Display model selection GUI\n",
                "    selected_model_name = select_model_gui(features=X_train.columns.tolist(), label=label_for_gui)\n",
                "\n",
                "    if selected_model_name:\n",
                "        model = get_model(selected_model_name, X_train)        \n",
                "        task_type = \"classification\" if is_classifier(model) else \"regression\"\n",
                "        result = train_and_evaluate_model(\n",
                "            model,\n",
                "            X_train,\n",
                "            X_test,\n",
                "            y_train_numeric if task_type == \"regression\" else y_train,\n",
                "            y_test_numeric if task_type == \"regression\" else y_test,\n",
                "            task_type=task_type,\n",
                "            target_column=y_train.name\n",
                "        )\n",
                "        trained_models.append(result)\n",
                "        print(f\"\\n✅ Model {selected_model_name} trained and evaluated successfully!\\n\")\n",
                "    else:\n",
                "        print(\"\\n🚫 No model was selected for this split.\")\n",
                "        \n",
                "print(y_train.value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aaea95a6",
            "metadata": {},
            "source": [
                "#### 7.4 Visualization of Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8993751b",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install matplotlib seaborn wordcloud"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "49b4d52d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from wordcloud import WordCloud\n",
                "from collections import Counter\n",
                "import numpy as np\n",
                "import re\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
                "import pandas as pd\n",
                "\n",
                "def visualize_model_results(trained_models):\n",
                "    for result in trained_models:\n",
                "        model = result[\"model\"]\n",
                "        y_test = result[\"y_test\"]\n",
                "        y_pred = result[\"y_pred\"]\n",
                "        \n",
                "        title = result.get(\"predictor\", \"Unknown Model\")\n",
                "        label_encoder = result.get(\"label_encoder\", None)\n",
                "\n",
                "        is_classifier = hasattr(model, \"predict_proba\") or hasattr(model, \"classes_\")\n",
                "        is_regressor = not is_classifier\n",
                "\n",
                "        is_text_classification = False\n",
                "        if is_classifier and isinstance(result.get(\"features\"), list):\n",
                "            features = result[\"features\"]\n",
                "            if len(features) == 1 and features[0].lower() == \"sentence\":\n",
                "                feature_name = \"sentence\"\n",
                "                label_name = \"tag\"\n",
                "                is_text_classification = True\n",
                "\n",
                "        if is_classifier:\n",
                "            if is_text_classification:\n",
                "                print(f\"Detected text classification task (feature='{feature_name}', label='{label_name}') - Generating WordCloud...\")\n",
                "\n",
                "                # Decode predicted labels\n",
                "                if label_encoder is not None:\n",
                "                    y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
                "                else:\n",
                "                    y_pred_decoded = y_pred\n",
                "\n",
                "                pred_counter = Counter(y_pred_decoded)\n",
                "\n",
                "                # WordCloud from input sentence content\n",
                "                X_test = result.get(\"X_test\")\n",
                "\n",
                "                if isinstance(X_test, pd.DataFrame) and \"sentence\" in X_test.columns:\n",
                "                    sentences = X_test[\"sentence\"].astype(str).tolist()\n",
                "                else:\n",
                "                    features = result.get(\"features_matrix\")\n",
                "                    if features is not None:\n",
                "                        sentences = [\" \".join(map(str, row)) for row in features]\n",
                "                    else:\n",
                "                        sentences = []\n",
                "\n",
                "                text_blob = \" \".join(sentences)\n",
                "                words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text_blob.lower())\n",
                "                filtered_words = [word for word in words if word not in ENGLISH_STOP_WORDS]\n",
                "                word_freq = Counter(filtered_words)\n",
                "\n",
                "                wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
                "                                        colormap='viridis', max_words=100).generate_from_frequencies(word_freq)\n",
                "\n",
                "                plt.figure(figsize=(12, 6))\n",
                "                plt.imshow(wordcloud, interpolation='bilinear')\n",
                "                plt.axis('off')\n",
                "                plt.title(f\"WordCloud of Input Sentences - {title}\")\n",
                "                plt.tight_layout()\n",
                "                plt.show()\n",
                "\n",
                "                # Bar plot: overall predicted tag distribution\n",
                "                tag_dist = Counter(y_pred_decoded)\n",
                "                tag_df = pd.DataFrame(tag_dist.items(), columns=[\"Tag\", \"Count\"]).sort_values(by=\"Count\", ascending=False)\n",
                "\n",
                "                plt.figure(figsize=(10, 5))\n",
                "                sns.barplot(data=tag_df, x=\"Tag\", y=\"Count\", palette=\"crest\")\n",
                "                plt.title(f\"Distribution of Predicted Tags - {title}\")\n",
                "                plt.xlabel(\"Tag\")\n",
                "                plt.ylabel(\"Count\")\n",
                "                plt.xticks(rotation=45, ha='right')\n",
                "                plt.tight_layout()\n",
                "                plt.show()\n",
                "\n",
                "            else:\n",
                "                # Structured Classification -> Confusion Matrix\n",
                "                cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "                if label_encoder is not None:\n",
                "                    class_labels = label_encoder.inverse_transform(np.arange(len(label_encoder.classes_)))\n",
                "                else:\n",
                "                    class_labels = [str(i) for i in range(cm.shape[0])]\n",
                "\n",
                "                plt.figure(figsize=(14, 10))\n",
                "                sns.heatmap(cm, xticklabels=class_labels, yticklabels=class_labels,\n",
                "                            annot=True, fmt='d', cmap=\"YlGnBu\", cbar=False)\n",
                "                plt.xlabel('Predicted Label')\n",
                "                plt.ylabel('True Label')\n",
                "                plt.title(f'Confusion Matrix - {title} Classifier')\n",
                "                plt.xticks(rotation=45, ha='right')\n",
                "                plt.yticks(rotation=0)\n",
                "                plt.tight_layout()\n",
                "                plt.show()\n",
                "\n",
                "        elif is_regressor:\n",
                "            residuals = np.array(y_test) - np.array(y_pred)\n",
                "\n",
                "            # Predicted vs Actual\n",
                "            plt.figure(figsize=(10, 6))\n",
                "            sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)\n",
                "            plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label='Perfect Prediction')\n",
                "            plt.xlabel(\"True Values\")\n",
                "            plt.ylabel(\"Predicted Values\")\n",
                "            plt.title(f\"Predicted vs Actual - {title} Regressor\")\n",
                "            plt.legend()\n",
                "            plt.grid(True)\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "\n",
                "            # Residual Plot\n",
                "            plt.figure(figsize=(10, 6))\n",
                "            sns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\n",
                "            plt.axhline(0, color='red', linestyle='--')\n",
                "            plt.xlabel(\"Predicted Values\")\n",
                "            plt.ylabel(\"Residuals (True - Predicted)\")\n",
                "            plt.title(f\"Residual Plot - {title} Regressor\")\n",
                "            plt.grid(True)\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "\n",
                "            # Error Distribution\n",
                "            plt.figure(figsize=(10, 6))\n",
                "            sns.histplot(residuals, kde=True, bins=30)\n",
                "            plt.title(f\"Distribution of Errors - {title} Regressor\")\n",
                "            plt.xlabel(\"Prediction Error\")\n",
                "            plt.grid(True)\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "\n",
                "visualize_model_results(trained_models)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d264d10f",
            "metadata": {},
            "source": [
                "#### 7.5 Prediction on Unseen Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f93a5bed",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.base import ClassifierMixin, RegressorMixin\n",
                "\n",
                "# --- Prediction Function --- \n",
                "def predict_unseen_data(model_index, input_data):\n",
                "    model_info = trained_models[model_index]\n",
                "    model = model_info[\"model\"]\n",
                "    original_features = model_info[\"features\"]\n",
                "    X_train_encoded_columns = model_info[\"X_train_columns\"]\n",
                "    \n",
                "    # Get the encoded features from the model\n",
                "    encoded_features = model_info[\"X_train_encoded\"]\n",
                "\n",
                "    try:\n",
                "        input_df = pd.DataFrame([input_data], columns=original_features)\n",
                "\n",
                "        # Handle categorical encoding\n",
                "        categorical_features = [col for col in input_df.columns if input_df[col].dtype == object]\n",
                "        if categorical_features:\n",
                "            if (len(categorical_features) == 1 and categorical_features[0] == \"sentence\" and model_info.get(\"predictor\") == \"tag\"):\n",
                "                # If the input is a text classification task, we need to vectorize the text data\n",
                "                vectorizer = model_info.get(\"vectorizer\")  # Retrieve the fitted vectorizer from the model\n",
                "                if vectorizer is None:\n",
                "                    raise ValueError(\"TF-IDF Vectorizer is not fitted or saved during training.\")\n",
                "                input_encoded = vectorizer.transform(input_df[\"sentence\"]).toarray()  # Convert to dense array\n",
                "                input_df_encoded = pd.DataFrame(input_encoded, columns=X_train_encoded_columns)\n",
                "            else:\n",
                "                input_encoded = pd.get_dummies(input_df, columns=categorical_features)\n",
                "                input_df_encoded = input_encoded.copy()\n",
                "        else:\n",
                "            input_df_encoded = input_df.copy()\n",
                "            \n",
                "        input_aligned = input_df_encoded.reindex(columns=X_train_encoded_columns, fill_value=0)\n",
                "\n",
                "        if input_aligned.isnull().values.any() or input_aligned.empty:\n",
                "            raise ValueError(\"Input data is empty after preprocessing. Please check the input fields.\")\n",
                "\n",
                "        prediction = model.predict(input_aligned)[0]\n",
                "\n",
                "        confidence = None\n",
                "        label = None\n",
                "\n",
                "        # --- Handle Classifiers ---\n",
                "        if isinstance(model, ClassifierMixin):\n",
                "            if hasattr(model, \"predict_proba\"):\n",
                "                proba = model.predict_proba(input_aligned)[0]\n",
                "                predicted_class_idx = model.classes_.tolist().index(prediction)\n",
                "                confidence = proba[predicted_class_idx]\n",
                "            elif hasattr(model, \"kneighbors\"):\n",
                "                distances, _ = model.kneighbors(input_aligned)\n",
                "                max_distance = np.max(distances)\n",
                "                confidence = 1.0 - (max_distance / (max_distance + 1e-5))\n",
                "            else:\n",
                "                confidence = 0.0  # fallback\n",
                "\n",
                "            label_encoder = model_info.get(\"label_encoder\")\n",
                "            if label_encoder:\n",
                "                label = label_encoder.inverse_transform([prediction])[0]\n",
                "            else:\n",
                "                label = str(prediction)\n",
                "\n",
                "        # --- Handle Regressors ---\n",
                "        elif isinstance(model, RegressorMixin):\n",
                "            label = float(prediction)\n",
                "\n",
                "            # Calculate a pseudo-confidence based on training target spread\n",
                "            y_train = model_info.get(\"y_train\")\n",
                "            if y_train is not None and len(y_train) > 1:\n",
                "                y_min, y_max = np.min(y_train), np.max(y_train)\n",
                "                if y_max != y_min:\n",
                "                    normalized_prediction = (prediction - y_min) / (y_max - y_min)\n",
                "                    confidence = 1.0 - abs(0.5 - normalized_prediction) * 2  # closer to center is more confident\n",
                "                    confidence = max(0.0, min(1.0, confidence))\n",
                "                else:\n",
                "                    confidence = 0.0\n",
                "            else:\n",
                "                confidence = 0.0\n",
                "\n",
                "        else:\n",
                "            raise ValueError(\"Unsupported model type.\")\n",
                "\n",
                "        confidence_percentage = round(confidence * 100, 2)\n",
                "        return label, confidence_percentage\n",
                "\n",
                "    except Exception as e:\n",
                "        error_msg = f\"❌ Error while predicting:\\n{e}\"\n",
                "        print(error_msg)\n",
                "        messagebox.showerror(\"Prediction Error\", error_msg)\n",
                "        return None, None\n",
                "\n",
                "\n",
                "    except Exception as e:\n",
                "        error_msg = f\"❌ Error while predicting:\\n{e}\"\n",
                "        print(error_msg)\n",
                "        messagebox.showerror(\"Prediction Error\", error_msg)\n",
                "        return None, None\n",
                "\n",
                "# --- Tkinter GUI Functions ---\n",
                "def update_fields_for_model(model_index):\n",
                "    try:\n",
                "        for widget in feature_frame.winfo_children():\n",
                "            widget.destroy()\n",
                "        input_entries.clear()\n",
                "\n",
                "        model_info = trained_models[model_index]\n",
                "        model_predictor = model_info[\"predictor\"]\n",
                "        model_features = model_info[\"features\"]\n",
                "\n",
                "        model_info_label.config(\n",
                "            text=f\"Model to Predict: {model_predictor} (based on {', '.join(model_features)})\"\n",
                "        )\n",
                "\n",
                "        for feature in model_features:\n",
                "            tk.Label(feature_frame, text=feature).pack(anchor='w')\n",
                "            entry = tk.Entry(feature_frame, width=30)\n",
                "            entry.pack(anchor='w')\n",
                "            input_entries.append(entry)\n",
                "\n",
                "        model_var.set(str(model_index))\n",
                "\n",
                "    except Exception as e:\n",
                "        messagebox.showerror(\"Error\", f\"An error occurred while updating fields:\\n{e}\")\n",
                "\n",
                "def predict():\n",
                "    try:\n",
                "        model_index = int(model_var.get())\n",
                "        input_data = {}\n",
                "\n",
                "        for feature, entry in zip(trained_models[model_index][\"features\"], input_entries):\n",
                "            value = entry.get().strip()\n",
                "            if value == '':\n",
                "                messagebox.showwarning(\"Missing Input\", \"Please fill all feature fields before predicting.\")\n",
                "                return\n",
                "            try:\n",
                "                if '.' in value:\n",
                "                    input_data[feature] = float(value)\n",
                "                else:\n",
                "                    input_data[feature] = int(value)\n",
                "            except ValueError:\n",
                "                input_data[feature] = value.lower()\n",
                "\n",
                "        prediction, confidence = predict_unseen_data(model_index, input_data)\n",
                "\n",
                "        output_text.delete(\"1.0\", tk.END)\n",
                "        if prediction is not None:\n",
                "            result_msg = f\"✅ Prediction: {prediction}\\n\"\n",
                "            result_msg += f\"🔍 Confidence: {confidence}%\"\n",
                "            output_text.insert(tk.END, result_msg)\n",
                "        else:\n",
                "            output_text.insert(tk.END, \"❌ Prediction failed. See error messages.\")\n",
                "\n",
                "    except Exception as e:\n",
                "        messagebox.showerror(\"Input Error\", f\"Invalid input:\\n{e}\")\n",
                "\n",
                "def predict_with_unseen_input_gui():\n",
                "    global model_var, feature_frame, input_entries, output_text, model_info_label\n",
                "\n",
                "    window = tk.Tk()\n",
                "    window.title(\"Predict Unseen Data\")\n",
                "\n",
                "    def on_closing():\n",
                "        window.quit()\n",
                "        window.destroy()\n",
                "\n",
                "    window.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
                "\n",
                "    model_var = tk.StringVar()\n",
                "\n",
                "    model_info_label = tk.Label(window, text=\"\", font=(\"Arial\", 10, \"bold\"), wraplength=400, justify=\"left\")\n",
                "    model_info_label.pack(pady=5)\n",
                "\n",
                "    model_buttons_frame = tk.Frame(window)\n",
                "    model_buttons_frame.pack(pady=5)\n",
                "\n",
                "    for index, model_info in enumerate(trained_models):\n",
                "        model_name = model_info[\"model\"].__class__.__name__\n",
                "        model_predictor = model_info[\"predictor\"]\n",
                "        model_features = model_info[\"features\"]\n",
                "        button_text = f\"Model: {model_name}\\nPredictor: {model_predictor}\\nFeatures: {', '.join(model_features)}\"\n",
                "\n",
                "        tk.Button(\n",
                "            model_buttons_frame,\n",
                "            text=button_text,\n",
                "            command=lambda idx=index: update_fields_for_model(idx),\n",
                "            width=40,\n",
                "            height=5,\n",
                "            anchor=\"w\",\n",
                "            justify=\"left\",\n",
                "            wraplength=350\n",
                "        ).pack(pady=3)\n",
                "\n",
                "    feature_frame = tk.Frame(window)\n",
                "    feature_frame.pack(pady=10)\n",
                "\n",
                "    input_entries = []\n",
                "\n",
                "    tk.Button(window, text=\"🚀 Predict\", command=predict).pack(pady=5)\n",
                "\n",
                "    output_text = tk.Text(window, height=6, width=60)\n",
                "    output_text.pack(pady=10)\n",
                "\n",
                "    window.mainloop()\n",
                "\n",
                "# 🚀 Launch GUI\n",
                "predict_with_unseen_input_gui()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "126676ab",
            "metadata": {},
            "source": [
                "### Step 8: Export Trained Model(s)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "74c6e497",
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "\n",
                "# File path\n",
                "model_file = \"models.pkl\"\n",
                "\n",
                "all_models = []\n",
                "\n",
                "# Check if models.pkl exists\n",
                "if os.path.exists(model_file):\n",
                "    # Load existing models\n",
                "    all_models = joblib.load(model_file)\n",
                "\n",
                "# Extend the list properly\n",
                "all_models.extend(trained_models)\n",
                "\n",
                "# Save the updated models list back to models.pkl\n",
                "joblib.dump(all_models, model_file)\n",
                "\n",
                "print(f\"✅ Models saved successfully! Total models now: {len(all_models)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c823a705",
            "metadata": {},
            "source": [
                "(Optional) : Load trained models from `models.pkl`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1993d31",
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "import os\n",
                "\n",
                "# File path\n",
                "model_file = \"models.pkl\"\n",
                "\n",
                "# Check if models.pkl exists\n",
                "if os.path.exists(model_file):\n",
                "    # Load existing models\n",
                "    \n",
                "    # should show: <class 'list'>\n",
                "    existing_models = joblib.load(model_file)\n",
                "    print(type(existing_models)) \n",
                "\n",
                "    # should show: <class 'dict'>\n",
                "    print(type(existing_models[0]))\n",
                "    \n",
                "    print(f\"Number of Models : {len(existing_models)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "59cd6b24",
            "metadata": {},
            "source": [
                "### - END"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
